\section{Análisis de resultados}

Para comenzar, de cara a realizar el análisis de resultados, se han realizado resúmenes de los resultados obtenidos, utilizando las medias de las ejecuciones y los mejores resultados obtenidos.

Utilizando dichos resúmenes para interpretar de una forma más sencilla los resultados, se discutirán distintos aspectos de estos:

\begin{enumerate}
	\item Diferencias según la función de ajuste utilizada.
	\item Comparación entre los distintos algoritmos utilizados.
	\item Diferencias según la técnica de sobremuestreo utilizada.
	\item Comparación con otras técnicas del estado del arte.
\end{enumerate}

Además, por último se realizará un análisis del uso de características, de cara a encontrar que atributos se han utilizado más y así estudiar si alguno de estos atributos no es necesario.

En este análisis, para referirse a los algoritmos y sus ejecuciones se seguirá la siguiente nomenclatura: \texttt{<ALG>-<OVERSAMPLING>-<FITNESS>}. Donde, \texttt{ALG} será el algoritmo de Programación Genética utilizado:

\begin{itemize}
	\item BJOR: Algoritmo de Bjorczuk.
	\item FALCO: Algoritmo de Falco.
	\item TAN: Algoritmo de Tan.
\end{itemize}

\texttt{OVERSAMPLING} será la técnica de balanceo de clases utilizada:

\begin{itemize}
	\item ROS: Sobremuestro aleatorio (Random Over Sampling).
	\item SMOTE: El algoritmo SMOTE.
	\item BLSMOTE: El algoritmo BorderlineSMOTE.
\end{itemize}

\texttt{FITNESS} será la función de ajuste utilizada durante el entrenamiento del algoritmo:

\begin{itemize}
	\item OMAE.
	\item MMAE.
	\item AMAE.
\end{itemize}

De forma que, por ejemplo, TAN-SMOTE-OMAE quiere decir que se refiere a los resultados obtenidos por el algoritmo de Tan, utilizando el conjunto de datos con sobremuestro usando SMOTE, y entrenado con OMAE como función de ajuste.

Se ha decidido no incluir los resultados con la función de ajuste original de cada algoritmo ya que se ha visto que con dicha función de ajuste los algoritmos no son capaces de encontrar soluciones competentes al problema, e incluirlos en este análisis solo lo extendería innecesariamente.

\subsection{Resumen de los resultados}

Vamos a comenzar con una tabla a modo de resumen general de todas las ejecuciones. Esta tabla contiene los resultados en media de todos los algoritmos, técnicas de sobremuestro y funciones de ajuste utilizadas.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{Tabla con un resumen de los resultados en media obtenidos por todas las ejecuciones.}}                                                                                                                                                               \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{}}}  & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                        & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                            & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}}    & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-ROS-OMAE}}      & \multicolumn{1}{c|}{1,8573}          & \multicolumn{1}{c|}{1,9112}            & \multicolumn{1}{c|}{1,9691}         & \multicolumn{1}{c|}{0,2216}           & \multicolumn{1}{c|}{0,2080}             & 0,0927       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-OMAE}}    & \multicolumn{1}{c|}{1,7362}           & \multicolumn{1}{c|}{1,6805}             & \multicolumn{1}{c|}{1,7972}          & \multicolumn{1}{c|}{0,2544}           & \multicolumn{1}{c|}{0,2518}              & 0,0968       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-BLSMOTE-OMAE}}  & \multicolumn{1}{c|}{2,1888}           & \multicolumn{1}{c|}{2,1557}             & \multicolumn{1}{c|}{2,1569}          & \multicolumn{1}{c|}{0,1796}            & \multicolumn{1}{c|}{0,1715}             & 0,1135       \\ \hline \hline
\multicolumn{1}{|c|}{\textbf{BJOR-ROS-MMAE}}      & \multicolumn{1}{c|}{2,0320}          & \multicolumn{1}{c|}{2,0497}            & \multicolumn{1}{c|}{2,3816}         & \multicolumn{1}{c|}{0,1938}           & \multicolumn{1}{c|}{0,1816}             & 0,0885       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-MMAE}}    & \multicolumn{1}{c|}{2,6121}           & \multicolumn{1}{c|}{2,6252}             & \multicolumn{1}{c|}{2,4246}          & \multicolumn{1}{c|}{0,2247}           & \multicolumn{1}{c|}{0,2219}             & 0,1125        \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-BLSMOTE-MMAE}}  & \multicolumn{1}{c|}{2,6709}            & \multicolumn{1}{c|}{2,6776}             & \multicolumn{1}{c|}{2,4960}          & \multicolumn{1}{c|}{0,1381}           & \multicolumn{1}{c|}{0,1255}             & 0,1010       \\ \hline \hline
\multicolumn{1}{|c|}{\textbf{BJOR-ROS-AMAE}}      & \multicolumn{1}{c|}{2,1410}           & \multicolumn{1}{c|}{2,1938}             & \multicolumn{1}{c|}{2,0212}          & \multicolumn{1}{c|}{0,2336}           & \multicolumn{1}{c|}{0,2212}             & 0,1864       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-AMAE}}    & \multicolumn{1}{c|}{2,4353}           & \multicolumn{1}{c|}{2,4740}             & \multicolumn{1}{c|}{2,3815}           & \multicolumn{1}{c|}{0,1595}           & \multicolumn{1}{c|}{0,1579}              & 0,0854       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-BLSMOTE-AMAE}}  & \multicolumn{1}{c|}{2,4353}           & \multicolumn{1}{c|}{2,4740}             & \multicolumn{1}{c|}{2,3815}           & \multicolumn{1}{c|}{0,1595}           & \multicolumn{1}{c|}{0,1579}              & 0,0854       \\ \hline \hline
\multicolumn{1}{|c|}{\textbf{FALCO-ROS-OMAE}}     & \multicolumn{1}{c|}{1,8201}           & \multicolumn{1}{c|}{1,8741}             & \multicolumn{1}{c|}{1,7541}          & \multicolumn{1}{c|}{0,3258}            & \multicolumn{1}{c|}{0,3118}             & 0,2218       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-SMOTE-OMAE}}   & \multicolumn{1}{c|}{1,9551}           & \multicolumn{1}{c|}{1,9139}             & \multicolumn{1}{c|}{1,8394}          & \multicolumn{1}{c|}{0,3214}            & \multicolumn{1}{c|}{0,3212}             & 0,2531       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-BLSMOTE-OMAE}} & \multicolumn{1}{c|}{1,7912}           & \multicolumn{1}{c|}{1,8748}             & \multicolumn{1}{c|}{2,033}            & \multicolumn{1}{c|}{0,3634}           & \multicolumn{1}{c|}{0,3428}              & 0,1708       \\ \hline \hline
\multicolumn{1}{|c|}{\textbf{TAN-ROS-OMAE}}       & \multicolumn{1}{c|}{1,5948}           & \multicolumn{1}{c|}{1,5746}             & \multicolumn{1}{c|}{\textbf{1,5856}} & \multicolumn{1}{c|}{0,2566}           & \multicolumn{1}{c|}{0,2568}             & 0,1896        \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-SMOTE-OMAE}}     & \multicolumn{1}{c|}{1,4658}           & \multicolumn{1}{c|}{1,4912}             & \multicolumn{1}{c|}{1,6448}          & \multicolumn{1}{c|}{0,2922}           & \multicolumn{1}{c|}{0,2719}             & 0,2145       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-BLSMOTE-OMAE}}   & \multicolumn{1}{c|}{1,4595}           & \multicolumn{1}{c|}{1,5016}             & \multicolumn{1}{c|}{1,7807}          & \multicolumn{1}{c|}{0,2950}           & \multicolumn{1}{c|}{0,2780}             & 0,1822       \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con todas las ejecuciones realizadas.}
\end{table}

Aunque esta tabla sigue siendo demasiado grande como para intentar utilizarla en todas las secciones, si que agrupa todas las ejecuciones realizadas a lo largo de la experimentación. En los siguientes apartados se utilizarán tablas obtenidas a partir de esta tabla general para realizar las comparativas entre las distintas técnicas utilizadas.

\subsection{Importancia de la función de ajuste en este problema}

Para comenzar con este análisis de resultados vamos a comentar la importancia de la función de ajuste de los algoritmos a la hora de resolver el problema.

Uno de los problemas encontrados al realizar la experimentación ha sido los malos resultados iniciales obtenidos por los tres algoritmos utilizados, independientemente de si utilizaban un enfoque Michigan, un enfoque híbrido, si escogían una única regla por clase, o si escogían más reglas por clase. Tras comprobar el comportamiento de los tres algoritmos y analizar sus resultados, la conclusión es que no era capaz de aprender reglas para un problema complejo con los medios que contaba el algoritmo, por lo que se decidió cambiar la forma de explorar el espacio de búsqueda, adaptando dicha búsqueda para un problema de clasificación ordinal.

Este fue el motivo de que se estudiaran otras métricas como función de ajuste en los algoritmos, en concreto funciones utilizadas en problemas de clasificación ordinal:

\begin{itemize}
	\item OMAE.
	\item AMAE.
	\item MMAE.
\end{itemize}

Y aunque las dos últimas solo se han podido aplicar al algoritmo de Bjorczuk (ya que el algoritmo de Tan y el de Falco aprenden las clases por separado), el comportamiento ha sido el siguiente, separando los resultados por función de ajuste utilizada:

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ las ejecuciones con la función de ajuste original.\end{tabular}}}                                                                                     \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}           & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                            & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-ROS-ORIG}}      & \multicolumn{1}{c|}{3,2632}          & \multicolumn{1}{c|}{3,2596}             & \multicolumn{1}{c|}{3,2685}      & \multicolumn{1}{c|}{0,1007}           & \multicolumn{1}{c|}{0,1010}             & 0,1573        \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-ORIG}}    & \multicolumn{1}{c|}{2,6564}           & \multicolumn{1}{c|}{2,7200}             & \multicolumn{1}{c|}{2,7419}        & \multicolumn{1}{c|}{0,1947}           & \multicolumn{1}{c|}{0,1820}             & 0,0895       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-BLSMOTE-ORIG}}  & \multicolumn{1}{c|}{3,3474}           & \multicolumn{1}{c|}{3,3498}              & \multicolumn{1}{c|}{3,3594}       & \multicolumn{1}{c|}{0,1002}           & \multicolumn{1}{c|}{0,0985}             & 0,1854        \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-ROS-ORIG}}     & \multicolumn{1}{c|}{4,3313}           & \multicolumn{1}{c|}{4,3385}             & \multicolumn{1}{c|}{4,3895}        & \multicolumn{1}{c|}{0,1733}           & \multicolumn{1}{c|}{0,1716}             & 0,0510       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-SMOTE-ORIG}}   & \multicolumn{1}{c|}{4,2311}           & \multicolumn{1}{c|}{4,2311}             & \multicolumn{1}{c|}{4,2923}       & \multicolumn{1}{c|}{0,2010}           & \multicolumn{1}{c|}{0,2010}             & 0,0677        \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-BLSMOTE-ORIG}} & \multicolumn{1}{c|}{4,3344}           & \multicolumn{1}{c|}{4,3502}             & \multicolumn{1}{c|}{4,2869}       & \multicolumn{1}{c|}{0,1492}           & \multicolumn{1}{c|}{0,1410}             & 0,0687       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-ROS-ORIG}}       & \multicolumn{1}{c|}{3,9962}           & \multicolumn{1}{c|}{3,9788}             & \multicolumn{1}{c|}{4,0425}       & \multicolumn{1}{c|}{0,0951}            & \multicolumn{1}{c|}{0,0959}              & 0,1781       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-SMOTE-ORIG}}     & \multicolumn{1}{c|}{3,9326}           & \multicolumn{1}{c|}{3,9661}             & \multicolumn{1}{c|}{4,0411}       & \multicolumn{1}{c|}{0,1098}            & \multicolumn{1}{c|}{0,1039}             & 0,3354       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-BLSMOTE-ORIG}}   & \multicolumn{1}{c|}{4,4829}           & \multicolumn{1}{c|}{4,4909}             & \multicolumn{1}{c|}{4,44}          & \multicolumn{1}{c|}{0,1001}            & \multicolumn{1}{c|}{0,0999}             & 0,3594        \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados usando la función de ajuste propuesta en cada algoritmo.}\label{resumenDEFECTO}
\end{table}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ las ejecuciones con la función de ajuste OMAE.\end{tabular}}}                                                                                     \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}           & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                            & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-ROS-OMAE}}      & \multicolumn{1}{c|}{1,8573}          & \multicolumn{1}{c|}{1,9112}            & \multicolumn{1}{c|}{1,9691}      & \multicolumn{1}{c|}{0,2216}           & \multicolumn{1}{c|}{0,2080}             & 0,0927       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-OMAE}}    & \multicolumn{1}{c|}{1,7362}           & \multicolumn{1}{c|}{1,6805}             & \multicolumn{1}{c|}{1,7972}       & \multicolumn{1}{c|}{0,2544}           & \multicolumn{1}{c|}{0,2518}              & 0,0968       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-BLSMOTE-OMAE}}  & \multicolumn{1}{c|}{2,1888}           & \multicolumn{1}{c|}{2,1557}             & \multicolumn{1}{c|}{2,1569}       & \multicolumn{1}{c|}{0,1796}            & \multicolumn{1}{c|}{0,1715}             & 0,1135       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-ROS-OMAE}}     & \multicolumn{1}{c|}{1,8201}           & \multicolumn{1}{c|}{1,8741}             & \multicolumn{1}{c|}{1,7541}       & \multicolumn{1}{c|}{0,3258}            & \multicolumn{1}{c|}{0,3118}             & 0,2218       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-SMOTE-OMAE}}   & \multicolumn{1}{c|}{1,9551}           & \multicolumn{1}{c|}{1,9139}             & \multicolumn{1}{c|}{1,8394}       & \multicolumn{1}{c|}{0,3214}            & \multicolumn{1}{c|}{0,3212}             & 0,2531       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-BLSMOTE-OMAE}} & \multicolumn{1}{c|}{1,7912}           & \multicolumn{1}{c|}{1,8748}             & \multicolumn{1}{c|}{2,033}         & \multicolumn{1}{c|}{0,3634}           & \multicolumn{1}{c|}{0,3428}              & 0,1708       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-ROS-OMAE}}       & \multicolumn{1}{c|}{1,5948}           & \multicolumn{1}{c|}{1,5746}             & \multicolumn{1}{c|}{1,5856}       & \multicolumn{1}{c|}{0,2566}           & \multicolumn{1}{c|}{0,2568}             & 0,1896        \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-SMOTE-OMAE}}     & \multicolumn{1}{c|}{1,4658}           & \multicolumn{1}{c|}{1,4912}             & \multicolumn{1}{c|}{1,6448}       & \multicolumn{1}{c|}{0,2922}           & \multicolumn{1}{c|}{0,2719}             & 0,2145       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-BLSMOTE-OMAE}}   & \multicolumn{1}{c|}{1,4595}           & \multicolumn{1}{c|}{1,5016}             & \multicolumn{1}{c|}{1,7807}       & \multicolumn{1}{c|}{0,2950}           & \multicolumn{1}{c|}{0,2780}             & 0,1822       \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados usando la función de ajuste OMAE.}\label{resumenOMAE}
\end{table}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ las ejecuciones con la función de ajuste MMAE.\end{tabular}}}                                                                                    \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}          & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                           & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-ROS-MMAE}}     & \multicolumn{1}{c|}{2,0320}          & \multicolumn{1}{c|}{2,0497}            & \multicolumn{1}{c|}{2,3816}      & \multicolumn{1}{c|}{0,1938}           & \multicolumn{1}{c|}{0,1816}             & 0,0885       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-MMAE}}   & \multicolumn{1}{c|}{2,6121}           & \multicolumn{1}{c|}{2,6252}             & \multicolumn{1}{c|}{2,4246}       & \multicolumn{1}{c|}{0,2247}           & \multicolumn{1}{c|}{0,2219}             & 0,1125        \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-BLSMOTE-MMAE}} & \multicolumn{1}{c|}{2,6709}            & \multicolumn{1}{c|}{2,6776}             & \multicolumn{1}{c|}{2,4960}       & \multicolumn{1}{c|}{0,1381}           & \multicolumn{1}{c|}{0,1255}             & 0,1010       \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados usando la función de ajuste MMAE.}\label{resumenMMAE}
\end{table}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ las ejecuciones con la función de ajuste AMAE.\end{tabular}}}                                                                                    \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}          & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                           & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-ROS-AMAE}}     & \multicolumn{1}{c|}{2,1410}           & \multicolumn{1}{c|}{2,1938}             & \multicolumn{1}{c|}{2,0212}       & \multicolumn{1}{c|}{0,2336}           & \multicolumn{1}{c|}{0,2212}             & 0,1864       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-AMAE}}   & \multicolumn{1}{c|}{2,4353}           & \multicolumn{1}{c|}{2,4740}             & \multicolumn{1}{c|}{2,3815}        & \multicolumn{1}{c|}{0,1595}           & \multicolumn{1}{c|}{0,1579}              & 0,0854       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-BLSMOTE-AMAE}} & \multicolumn{1}{c|}{2,4353}           & \multicolumn{1}{c|}{2,4740}             & \multicolumn{1}{c|}{2,3815}        & \multicolumn{1}{c|}{0,1595}           & \multicolumn{1}{c|}{0,1579}              & 0,0854       \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados usando la función de ajuste AMAE.}\label{resumenAMAE}
\end{table}


Como podemos ver en los resultados de la tabla \ref{resumenDEFECTO} en comparación con todas las demás ejecuciones usando métricas para clasificación ordinal (\ref{resumenOMAE}, \ref{resumenMMAE} y \ref{resumenAMAE}), y ya vimos en las matrices de confusión de los resultados, en ninguno de los algoritmos da buenos resultados la función de ajuste propuesta, independientemente del algoritmo concreto utilizado, siendo los resultados significativamente peores, y no siendo capaz ninguno de ellos de realizar predicciones complejas.

Por otro lado, comparando las tres métricas de clasificación ordinal para el algoritmo de Bjorczuk, la elección clara se trata de OMAE, ya que en los conjuntos de test y validación consigue unos resultados mejores que usando tanto MMAE como AMAE, llegando a veces a mejorar el OMAE en un $0.6$.

El haber realizado esta modificación de la función de ajuste, y que este cambio implique unas diferencias tan grandes en la ejecución del algoritmo nos lleva a la conclusión de la importancia de conocer el problema que estamos manejando. No se trata simplemente de conocer el dominio del problema y como se comportan los datos que utilizamos, también es importante adaptar los algoritmos al problema al que nos enfrentamos de cara a que la búsqueda por el espacio de soluciones sea coherente con el problema y lo que se busca.

Por simplicidad y debido a que claramente OMAE consigue unos mejores resultados, en las siguientes secciones nos limitaremos a utilizar los resultados obtenidos por los experimentos que han utilizado OMAE.


\subsection{Comparación entre los algoritmos utilizados}

En este apartado vamos a comparar los resultados de los tres algoritmos utilizados. En este caso, además de las métricas utilizadas, otra de las cosas que tenemos que tener en cuenta es la simplicidad de la solución, ya que aunque los algoritmos de Bjorczuk y de Falco como máximo tienen once reglas (una por clase y la regla por defecto), el algoritmo de Tan, como hemos visto en algunos resultados, puede generar clasificadores con un conjunto de reglas mucho más grande.


Vamos a comenzar observando las métricas de evaluación:

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ las ejecuciones del algoritmo de Bjorczuk.\end{tabular}}}                                                                                            \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}          & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                           & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-ROS-OMAE}}     & \multicolumn{1}{c|}{1,8573}          & \multicolumn{1}{c|}{1,9112}            & \multicolumn{1}{c|}{1,9691}      & \multicolumn{1}{c|}{0,2216}           & \multicolumn{1}{c|}{0,2080}             & 0,0927       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-OMAE}}   & \multicolumn{1}{c|}{1,7362}           & \multicolumn{1}{c|}{1,6805}             & \multicolumn{1}{c|}{1,7972}       & \multicolumn{1}{c|}{0,2544}           & \multicolumn{1}{c|}{0,2518}              & 0,0968       \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-BLSMOTE-OMAE}} & \multicolumn{1}{c|}{2,1888}           & \multicolumn{1}{c|}{2,1557}             & \multicolumn{1}{c|}{2,1569}       & \multicolumn{1}{c|}{0,1796}            & \multicolumn{1}{c|}{0,1715}             & 0,1135       \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados del algoritmo de Bjorczuk y la función de ajuste OMAE.}\label{resumenBjorczukOMAE}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ las ejecuciones del algoritmo de Falco.\end{tabular}}}                                                                                                \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}           & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                            & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-ROS-OMAE}}     & \multicolumn{1}{c|}{1,8201}           & \multicolumn{1}{c|}{1,8741}             & \multicolumn{1}{c|}{1,7541}       & \multicolumn{1}{c|}{0,3258}            & \multicolumn{1}{c|}{0,3118}             & 0,2218       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-SMOTE-OMAE}}   & \multicolumn{1}{c|}{1,9551}           & \multicolumn{1}{c|}{1,9139}             & \multicolumn{1}{c|}{1,8394}       & \multicolumn{1}{c|}{0,3214}            & \multicolumn{1}{c|}{0,3212}             & 0,2531       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-BLSMOTE-OMAE}} & \multicolumn{1}{c|}{1,7912}           & \multicolumn{1}{c|}{1,8748}             & \multicolumn{1}{c|}{2,033}         & \multicolumn{1}{c|}{0,3634}           & \multicolumn{1}{c|}{0,3428}              & 0,1708       \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados del algoritmo de Falco y la función de ajuste OMAE.}\label{resumenFalcoOMAE}

\end{table}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ las ejecuciones del algoritmo de Tan.\end{tabular}}}                                                                                                \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}         & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                          & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-ROS-OMAE}}     & \multicolumn{1}{c|}{1,5948}           & \multicolumn{1}{c|}{1,5746}             & \multicolumn{1}{c|}{1,5856}       & \multicolumn{1}{c|}{0,2566}           & \multicolumn{1}{c|}{0,2568}             & 0,1896        \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-SMOTE-OMAE}}   & \multicolumn{1}{c|}{1,4658}           & \multicolumn{1}{c|}{1,4912}             & \multicolumn{1}{c|}{1,6448}       & \multicolumn{1}{c|}{0,2922}           & \multicolumn{1}{c|}{0,2719}             & 0,2145       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-BLSMOTE-OMAE}} & \multicolumn{1}{c|}{1,4595}           & \multicolumn{1}{c|}{1,5016}             & \multicolumn{1}{c|}{1,7807}       & \multicolumn{1}{c|}{0,2950}           & \multicolumn{1}{c|}{0,2780}             & 0,1822       \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados del algoritmo de Tan y la función de ajuste OMAE.}\label{resumenTanOMAE}
\end{table}

Vemos en las tablas \ref{resumenBjorczukOMAE} y \ref{resumenFalcoOMAE} que los resultados de Bojarczuk y Falco son similares, y las diferencias en los resultados pueden deberse simplemente a la aleatoriedad de las ejecuciones, sin embargo vemos en el cuadro \ref{resumenTanOMAE} que el algoritmo de Tan si es más competitivo que los otros. Sin embargo, otro detalle que tenemos que observar, es el número de reglas obtenidas por el clasificador:

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[]
\centering
\begin{tabular}{|c|c|}
\hline
               & \textbf{\begin{tabular}[c]{@{}c@{}}N. Reglas en promedio\\  del modelo\end{tabular}} \\ \hline
\textbf{BJOR}  & 11                                                                                   \\ \hline
\textbf{FALCO} & 11                                                                                   \\ \hline
\textbf{TAN}   & 39                                                                                   \\ \hline
\end{tabular}%
\caption{Tabla resumen con el promedio de reglas obtenidas por cada modelo.}\label{resumenNReglas}
\end{table}

Si recordamos como funcionaban los distintos algoritmos, las puestas de Bjorczuk y Falco se limitaban a escoger una única regla por clase, mientras que el algoritmo de Tan escogía todas las reglas de la población elitista eliminando las repetidas. Este detalle hace que la solución encontrada por el algoritmo de Tan sea mucho más compleja y con una cantidad de reglas mucho mayor.

Aunque es cierto que los resultados en el conjunto de test son mejores (con una diferencia de $0.17$ en OMAE si comparamos el mejor resultado en media del algoritmo de Tan, con el mejor resultado en media obtenido por el algoritmo de Falco), una diferencia tan baja en OMAE es posible que no justifique la complejidad añadida de las soluciones propuestas.

\newpage

\subsection{Discusión sobre las técnicas de balanceo de clases aplicadas}

Por otra parte, para este problema también nos interesa tener una buena forma de tratar el desbalanceo de clases. Como se ha comentado con anterioridad, se han tomado tres enfoques distintos, dos de ellos basados en introducir instancias sintéticas:

\begin{enumerate}
	\item Sobremuestreo aleatorio: Repetir instancias de las clases minoritarias hasta que la distribución de observaciones por clase sea uniforme.
	\item SMOTE: Algoritmo para generar instancias sintéticas usando técnicas basadas en distancias.
	\item Borderline-SMOTE: Variante de SMOTE, centrada en generar instancias sintéticas en las fronteras de decisión.
\end{enumerate}

Vamos a analizar los resultados obtenidos por los tres algoritmos con los distintos enfoques para resolver este problema:

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ con el conjunto de datos al que se ha aplicado sobremuestro aleatorio.\end{tabular}}}                                                             \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}       & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                        & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-ROS-OMAE}}     & \multicolumn{1}{c|}{1,8573}          & \multicolumn{1}{c|}{1,9112}            & \multicolumn{1}{c|}{1,9691}      & \multicolumn{1}{c|}{0,2216}           & \multicolumn{1}{c|}{0,2080}             & 0,0927       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-ROS-OMAE}}    & \multicolumn{1}{c|}{1,8201}           & \multicolumn{1}{c|}{1,8741}             & \multicolumn{1}{c|}{1,7541}       & \multicolumn{1}{c|}{0,3258}            & \multicolumn{1}{c|}{0,3118}             & 0,2218       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-ROS-OMAE}}      & \multicolumn{1}{c|}{1,5948}           & \multicolumn{1}{c|}{1,5746}             & \multicolumn{1}{c|}{1,5856}       & \multicolumn{1}{c|}{0,2566}           & \multicolumn{1}{c|}{0,2568}             & 0,1896        \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados de aplicar sobremuestreo aleatorio.}\label{resumenROS}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ con el conjunto de datos al que se ha aplicado SMOTE.\end{tabular}}}                                                                                \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}         & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                          & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-OMAE}}   & \multicolumn{1}{c|}{1,7362}           & \multicolumn{1}{c|}{1,6805}             & \multicolumn{1}{c|}{1,7972}       & \multicolumn{1}{c|}{0,2544}           & \multicolumn{1}{c|}{0,2518}              & 0,0968       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-SMOTE-OMAE}}  & \multicolumn{1}{c|}{1,9551}           & \multicolumn{1}{c|}{1,9139}             & \multicolumn{1}{c|}{1,8394}       & \multicolumn{1}{c|}{0,3214}            & \multicolumn{1}{c|}{0,3212}             & 0,2531       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-SMOTE-OMAE}}    & \multicolumn{1}{c|}{1,4658}           & \multicolumn{1}{c|}{1,4912}             & \multicolumn{1}{c|}{1,6448}       & \multicolumn{1}{c|}{0,2922}           & \multicolumn{1}{c|}{0,2719}             & 0,2145       \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados de aplicar SMOTE.}\label{resumenSMOTE}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccc|}
\hline
\multicolumn{7}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Tabla con un resumen de los resultados en media obtenidos por \\ con el conjunto de datos al que se ha aplicado BL-SMOTE.\end{tabular}}}                                                                               \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{}}           & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                     & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                            \\ \cline{2-7}
\multicolumn{1}{|c|}{}                            & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}} & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \textbf{Test} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-BLSMOTE-OMAE}}  & \multicolumn{1}{c|}{2,1888}           & \multicolumn{1}{c|}{2,1557}             & \multicolumn{1}{c|}{2,1569}       & \multicolumn{1}{c|}{0,1796}            & \multicolumn{1}{c|}{0,1715}             & 0,1135       \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-BLSMOTE-OMAE}} & \multicolumn{1}{c|}{1,7912}           & \multicolumn{1}{c|}{1,8748}             & \multicolumn{1}{c|}{2,033}         & \multicolumn{1}{c|}{0,3634}           & \multicolumn{1}{c|}{0,3428}              & 0,1708       \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-BLSMOTE-OMAE}}   & \multicolumn{1}{c|}{1,4595}           & \multicolumn{1}{c|}{1,5016}             & \multicolumn{1}{c|}{1,7807}       & \multicolumn{1}{c|}{0,2950}           & \multicolumn{1}{c|}{0,2780}             & 0,1822       \\ \hline
\end{tabular}%
}
\caption{Tabla resumen con los resultados de aplicar BL-SMOTE.}\label{resumenBLSMOTE}
\end{table}



En este caso podemos ver comportamientos bastante distintos. Comenzando por el algoritmo de Bjorczuk, aplicar SMOTE en lugar de sobremuestro aleatorio ha mejorado los resultados notablemente, sin embargo, Borderline-SMOTE no ha funcionado. Por otro lado, tanto para el algoritmo de Falco como para el de Tan el uso de SMOTE y Borderline-SMOTE han empeorado los resultados obtenidos por sobremuestro aleatorio, siendo peores los resultados con Borderline-SMOTE.

Vamos a comenzar comentando el caso más claro, Borderline-SMOTE. El utilizar esta técnica para resolver el balanceo de clases ha dado peores resultados en todos los casos. Este comportamiento puede ser debido a que, al introducir datos sintéticos en las fronteras de decisión, se estén creando fronteras de decisión que no corresponden con las reales, y por lo tanto se cometa un mayor error.

Por otro lado, con respecto al comportamiento de los algoritmo al utilizar SMOTE, vemos dos comportamientos distintos, el del algoritmo de Bjorczuk, que mejora los resultados, y los algoritmos de Falco y de Tan, donde los resultados son peores. En este caso este comportamiento se puede explicar sabiendo como funcionan los algoritmos. El algoritmo de Bjorczuk, al trabajar con todas las clases en la misma ejecución, es capaz de tener en cuenta el solapamiento entre todas las clases y manejarlo en las reglas generadas, mientras que los algoritmo con un enfoque Michigan no son capaces de tener esto en cuenta, y generan reglas con un mayor solape.

Este estudio, además de poder comparar los resultados obtenidos, nos deja claro que la principal dificultad a la hora de obtener un buen resultado son las fronteras de decisión. Por un lado, si nos centramos en ellas, como en el caso de BL-SMOTE, es probable que las instancias sintéticas introduzcan ruido en lugar de aportar a la solución, debido a la falta de instancias originales con las que contamos, mientras que por otro lado tenemos que tener conocer lo suficiente los algoritmos que se utilizan como para saber si en realidad estamos ayudando al algoritmo a aprender o por el contrario estamos introduciéndole ruido.

\newpage

\subsection{Comparación con otras técnicas de aprendizaje automático avanzadas}

En esta sección vamos a realizar una comparación con otras técnicas de aprendizaje automático avanzadas, también utilizadas en otros trabajos del estado del arte. Para esta comparación se ha escogido la ejecución con mejores resultados de cada uno de los algoritmos utilizados:

\begin{itemize}
	\item BJOR-SMOTE-OMAE.
	\item FALCO-ROS-OMAE.
	\item TAN-ROS-OMAE.
\end{itemize}

Se ha decidido realizar esta comparación ya que en otros trabajos del estado del arte, como \cite{NSLVOrdAge}, hay diversos métodos que funcionan bastante bien y obtienen unos buenos resultados, sin embargo, debido a que la validación de experimentos es distinta y utilizan un conjunto de datos distinto, los resultados no son comparables. De cara a poder comparar los resultados obtenidos por estas técnicas, en este trabajo se ha replicado la experimentación que realizamos, pero usando estos algoritmos. En concreto son:

\begin{itemize}
	\item RandomForest con diez árboles: RF10 en la tabla de resultados.
	\item RandomForest con cien árboles: RF100 en la tabla de resultados.
	\item Redes neuronales profundas: DNN en la tabla comparativa. Red neuronal con dos capas ocultas de 64 neuronas cada capa, utilizando una activación ReLu y como optimizador Adam, con una tasa de aprendizaje de $0.003$, $\beta_1 = 0.9$ y $\beta_2 = 0.999$.
\end{itemize}

De cara a no alargar esta sección, ya que se buscan los resultados de estos algoritmos como comparación con los resultados obtenidos, se usará directamente los resultados obtenidos en media de los cinco folds. Los resultados son los siguientes:

\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|cccccccc|}
\hline
\multicolumn{8}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Resultados obtenidos por las técnicas del estado del arte\\ con nuestros conjuntos de datos\end{tabular}}}                                                                                                                                                                             \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{}}} & \multicolumn{3}{c|}{\textbf{OMAE}}                                                                                        & \multicolumn{3}{c|}{\textbf{Accuracy}}                                                                                    & \multirow{2}{*}{\textbf{N. reglas}} \\ \cline{2-7}
\multicolumn{1}{|c|}{}                           & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}}    & \multicolumn{1}{c|}{\textbf{Training}} & \multicolumn{1}{c|}{\textbf{Validacion}} & \multicolumn{1}{c|}{\textbf{Test}}    &                                     \\ \hline
\multicolumn{1}{|c|}{\textbf{RF10-ROS}}          & \multicolumn{1}{c|}{1,2965}            & \multicolumn{1}{c|}{1,4465}             & \multicolumn{1}{c|}{\textbf{1,3520}} & \multicolumn{1}{c|}{0,4752}           & \multicolumn{1}{c|}{0,3893}              & \multicolumn{1}{c|}{0,3916}          & \textbf{610,6}                      \\ \hline
\multicolumn{1}{|c|}{\textbf{RF100-ROS}}         & \multicolumn{1}{c|}{1,2825}            & \multicolumn{1}{c|}{1,4336}             & \multicolumn{1}{c|}{1,3541}          & \multicolumn{1}{c|}{0,4768}           & \multicolumn{1}{c|}{0,3853}             & \multicolumn{1}{c|}{0,3937}           & 6088,2                              \\ \hline
\multicolumn{1}{|c|}{\textbf{DNN-ROS}}           & \multicolumn{1}{c|}{1,3352}           & \multicolumn{1}{c|}{1,4636}              & \multicolumn{1}{c|}{1,3801}          & \multicolumn{1}{c|}{0,4638}           & \multicolumn{1}{c|}{0,3970}             & \multicolumn{1}{c|}{\textbf{0,3999}} & -                                   \\ \hline
\multicolumn{1}{|c|}{\textbf{RF10-SMOTE}}        & \multicolumn{1}{c|}{1,1150}           & \multicolumn{1}{c|}{1,1521}              & \multicolumn{1}{c|}{2,0760}          & \multicolumn{1}{c|}{0,4988}           & \multicolumn{1}{c|}{0,4798}             & \multicolumn{1}{c|}{0,2562}          & 666,2                               \\ \hline
\multicolumn{1}{|c|}{\textbf{RF100-SMOTE}}       & \multicolumn{1}{c|}{1,1148}           & \multicolumn{1}{c|}{1,1470}             & \multicolumn{1}{c|}{2,1374}          & \multicolumn{1}{c|}{0,5000}           & \multicolumn{1}{c|}{0,4816}             & \multicolumn{1}{c|}{0,2478}          & 6655,4                              \\ \hline
\multicolumn{1}{|c|}{\textbf{DNN-SMOTE}}         & \multicolumn{1}{c|}{1,1161}           & \multicolumn{1}{c|}{1,1661}             & \multicolumn{1}{c|}{2,0520}          & \multicolumn{1}{c|}{0,4922}           & \multicolumn{1}{c|}{0,4618}             & \multicolumn{1}{c|}{0,2572}          & -                                   \\ \hline
\multicolumn{1}{|c|}{\textbf{RF10-BLSMOTE}}      & \multicolumn{1}{c|}{1,1078}           & \multicolumn{1}{c|}{1,1729}             & \multicolumn{1}{c|}{2,3343}          & \multicolumn{1}{c|}{0,4864}           & \multicolumn{1}{c|}{0,4542}             & \multicolumn{1}{c|}{0,1718}          & 767,4                               \\ \hline
\multicolumn{1}{|c|}{\textbf{RF100-BLSMOTE}}     & \multicolumn{1}{c|}{1,1041}            & \multicolumn{1}{c|}{1,1604}              & \multicolumn{1}{c|}{2,3374}          & \multicolumn{1}{c|}{0,4884}           & \multicolumn{1}{c|}{0,4604}              & \multicolumn{1}{c|}{0,1739}          & 7726,8                              \\ \hline
\multicolumn{1}{|c|}{\textbf{DNN-BLSMOTE}}       & \multicolumn{1}{c|}{1,0842}            & \multicolumn{1}{c|}{1,1416}             & \multicolumn{1}{c|}{2,2197}          & \multicolumn{1}{c|}{0,4818}            & \multicolumn{1}{c|}{0,4524}             & \multicolumn{1}{c|}{0,1853}          & -                                   \\ \hline
\end{tabular}%
}
\end{table}

Como podemos ver en esta tabla de resultados, con estas técnicas si utilizamos un sobremuestreo que introduzca instancias sintéticas, como ocurre en SMOTE y BorderlineSMOTE, los algoritmos tienen un gran sobreajuste y los resultados obtenidos en el conjunto de test, donde no hay instancias sintéticas, empeora mucho. Por este motivo para la comparación con nuestros algoritmos utilizaremos los resultados con sobremuestreo aleatorio, ya que son los que mejor se comportan tanto en OMAE como en tasa de acierto:


% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[H]
\centering
\begin{tabular}{|cccc|}
\hline
\multicolumn{4}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Comparación de nuestros resultados con las\\ técnicas del estado del arte. Resultados en el conjunto de test.\end{tabular}}}    \\ \hline
\multicolumn{1}{|c|}{\textbf{}}                & \multicolumn{1}{c|}{\textbf{OMAE}}    & \multicolumn{1}{c|}{\textbf{Accuracy}} & \textbf{N. reglas} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-OMAE}} & \multicolumn{1}{c|}{1,7972}          & \multicolumn{1}{c|}{0,0968}           & \textbf{11}        \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-ROS-OMAE}}  & \multicolumn{1}{c|}{1,7541}          & \multicolumn{1}{c|}{0,2218}           & \textbf{11}        \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-ROS-OMAE}}    & \multicolumn{1}{c|}{1,5856}          & \multicolumn{1}{c|}{0,1896}            & 39                 \\ \hline
\multicolumn{1}{|c|}{\textbf{RF10-ROS}}        & \multicolumn{1}{c|}{\textbf{1,3520}} & \multicolumn{1}{c|}{0,3916}           & 610,6              \\ \hline
\multicolumn{1}{|c|}{\textbf{RF100-ROS}}       & \multicolumn{1}{c|}{1,3541}          & \multicolumn{1}{c|}{0,3937}            & 6088,2             \\ \hline
\multicolumn{1}{|c|}{\textbf{DNN-ROS}}         & \multicolumn{1}{c|}{1,3801}          & \multicolumn{1}{c|}{\textbf{0,3999}}  & -                  \\ \hline
\end{tabular}%
\end{table}


Aunque las técnicas utilizadas en este trabajo no llegan a alcanzar los resultados de técnicas más avanzadas en precisión y OMAE, nuestra propuesta es una solución mucho más sencilla e interpretable, ya que contamos con solo una regla por clase y la regla por defecto, siendo un sistema mucho más simple.

Es cierto que los resultados de Random Forest y redes neuronales profundas son los que mejores métricas obtienen tanto en OMAE como en tasa de acierto, sin embargo, como suele ocurrir en la gran mayoría de ocasiones, estos modelos con resultados muy buenos no son nada interpretables. Random Forest ha obtenido un total de $610$ reglas en media, algo que no es viable analizar por un experto y poder obtener conocimiento de dichos resultados, mientras que el modelo de red neuronal profunda, aunque existen formas de analizarlos y explicar el modelo a posteriori como se comenta en \cite{XAI}, sigue siendo un modelo de caja negra.

Con esta comparación podemos ver que, aunque no conseguimos unos resultados competitivos con respecto a modelos avanzados a nivel de OMAE y tasa de acierto, nuestra propuesta es la más competitiva con respecto a la complejidad del modelo final, manteniendo un OMAE bastante bueno, lo que puede ser de gran ayuda en ámbitos donde se busca que estos modelos sean una ayuda a la toma de decisiones y una fuente donde extraer conocimiento, como es el caso de este problema, en lugar de reemplazar al experto.

\newpage

\subsection{Comparación con el estado del arte}

En esta sección compararemos nuestros resultados con los resultados de \cite{NSLVOrdAge}, ya que se tratan de los mejores resultados del estado del arte tanto en OMAE y tasa de acierto como en interpretabilidad, además de permitirnos comparar las reglas obtenidas ya que también se trata de un conjunto de reglas para clasificación. En este trabajo, utilizando el algoritmo NSLVOrd para obtener un conjunto de reglas, obtienen unos buenos resultados con un conjunto de reglas pequeño, lo que permite que sea interpretable y se pueda extraer conocimiento de la solución propuesta.

Hay que tener en cuenta que esta comparación será aproximada debido a que las condiciones de la experimentación son distintas. En nuestro trabajo se ha dividido el conjunto de datos en entrenamiento y test, y sobre el entrenamiento se ha aplicado una validación cruzada de cinco folds, mientras que en \cite{NSLVOrdAge} se ha entrenado aplicado un 5x2-cv sobre las instancias de la lateralidad izquierda, y se ha usado como conjunto de test las instancias de la lateralidad derecha:


\begin{table}[H]
\centering
\begin{tabular}{|cccc|}
\hline
\multicolumn{4}{|c|}{\textbf{Comparación de nuestros resultados con NSLVOrd.}}    \\ \hline
\multicolumn{1}{|c|}{\textbf{}}                & \multicolumn{1}{c|}{\textbf{OMAE}}    & \multicolumn{1}{c|}{\textbf{Accuracy}} & \textbf{N. reglas} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-OMAE}} & \multicolumn{1}{c|}{1,7972}          & \multicolumn{1}{c|}{0,0968}           & \textbf{11}        \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-ROS-OMAE}}  & \multicolumn{1}{c|}{1,7541}          & \multicolumn{1}{c|}{0,2218}           & \textbf{11}        \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-ROS-OMAE}}    & \multicolumn{1}{c|}{\textbf{1,5856}}          & \multicolumn{1}{c|}{0,1896}            & 39                 \\ \hline
\multicolumn{1}{|c|}{\textbf{NSLVOrd}}        & \multicolumn{1}{c|}{1,754} & \multicolumn{1}{c|}{\textbf{0,298}}           & 34              \\ \hline
\end{tabular}%
\end{table}

En este caso, una solución muy parecida en el número de reglas final como es la del algoritmo de Tan obtiene mejores resultados en OMAE, mientras que conseguimos soluciones igual de competitivas a NSLVOrd pero con tan solo once reglas usando los algoritmos de Bjorczuk y de Tan, por lo que el uso de Programación Genética en este problema parece de gran interés.


La matriz de confusión de NSLVOrd sobre el conjunto de la lateralidad derecha es el siguiente:

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccccccccc|}
\hline
\multicolumn{13}{|c|}{\textbf{Matriz de confusión obtenida en NSLVOrd. Obtenida de \cite{NSLVOrdAge}}}                                                                                                                                                                                                                                                                                          \\ \hline
\multicolumn{2}{|c|}{\multirow{2}{*}{\textbf{}}}                                      & \multicolumn{10}{c|}{\textbf{Clase predicha}}                                                                                                                                                                                                                     & \multirow{2}{*}{} \\ \cline{3-12}
\multicolumn{2}{|c|}{}                                                                & \multicolumn{1}{c|}{C0} & \multicolumn{1}{c|}{C1} & \multicolumn{1}{c|}{C2} & \multicolumn{1}{c|}{C3} & \multicolumn{1}{c|}{C4} & \multicolumn{1}{c|}{C5} & \multicolumn{1}{c|}{C6} & \multicolumn{1}{c|}{C7} & \multicolumn{1}{c|}{C8} & \multicolumn{1}{c|}{C9} &                   \\ \hline
\multicolumn{1}{|c|}{\multirow{10}{*}{\textbf{Clase real}}} & \multicolumn{1}{c|}{C0} & \multicolumn{1}{c|}{\textbf{10}} & \multicolumn{1}{c|}{\textbf{2}}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & C0 = Ph01-19      \\ \cline{2-13}
\multicolumn{1}{|c|}{}                                      & \multicolumn{1}{c|}{C1} & \multicolumn{1}{c|}{\textbf{3}}  & \multicolumn{1}{c|}{\textbf{7}}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & C1 = Ph02-20-21   \\ \cline{2-13}
\multicolumn{1}{|c|}{}                                      & \multicolumn{1}{c|}{C2} & \multicolumn{1}{c|}{\textbf{2}}  & \multicolumn{1}{c|}{\textbf{2}}  & \multicolumn{1}{c|}{\textbf{8}}  & \multicolumn{1}{c|}{\textbf{1}}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & C2 = Ph03-22-24   \\ \cline{2-13}
\multicolumn{1}{|c|}{}                                      & \multicolumn{1}{c|}{C3} & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{5}}  & \multicolumn{1}{c|}{\textbf{5}}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & C3 = Ph04-25-26   \\ \cline{2-13}
\multicolumn{1}{|c|}{}                                      & \multicolumn{1}{c|}{C4} & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{5}}  & \multicolumn{1}{c|}{\textbf{26}} & \multicolumn{1}{c|}{\textbf{1}}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{2}}  & \multicolumn{1}{c|}{\textbf{1}}  & C4 = Ph05-27-30   \\ \cline{2-13}
\multicolumn{1}{|c|}{}                                      & \multicolumn{1}{c|}{C5} & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{3}}  & \multicolumn{1}{c|}{\textbf{19}} & \multicolumn{1}{c|}{\textbf{4}}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{4}}  & \multicolumn{1}{c|}{\textbf{1}}  & C5 = Ph06-31-34   \\ \cline{2-13}
\multicolumn{1}{|c|}{}                                      & \multicolumn{1}{c|}{C6} & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{13}} & \multicolumn{1}{c|}{\textbf{28}} & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{2}}  & \multicolumn{1}{c|}{\textbf{2}}  & \multicolumn{1}{c|}{\textbf{24}} & \multicolumn{1}{c|}{\textbf{6}}  & C6 = Ph07-35-39   \\ \cline{2-13}
\multicolumn{1}{|c|}{}                                      & \multicolumn{1}{c|}{C7} & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{3}}  & \multicolumn{1}{c|}{\textbf{28}} & \multicolumn{1}{c|}{\textbf{1}}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{3}}  & \multicolumn{1}{c|}{\textbf{17}} & \multicolumn{1}{c|}{\textbf{5}}  & C7 = Ph08-40-44   \\ \cline{2-13}
\multicolumn{1}{|c|}{}                                      & \multicolumn{1}{c|}{C8} & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{27}} & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{39}} & \multicolumn{1}{c|}{\textbf{3}}  & C8 = Ph09-45-49   \\ \cline{2-13}
\multicolumn{1}{|c|}{}                                      & \multicolumn{1}{c|}{C9} & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{4}}  & \multicolumn{1}{c|}{\textbf{54}} & \multicolumn{1}{c|}{\textbf{1}}  & \multicolumn{1}{c|}{0}  & \multicolumn{1}{c|}{\textbf{5}}  & \multicolumn{1}{c|}{\textbf{70}} & \multicolumn{1}{c|}{\textbf{41}} & C9 = Ph10-50-     \\ \hline
\end{tabular}%
}
\end{table}


Utilizaremos esta matriz de confusión y la obtenida por Tan para comentar y comparar algunos comportamientos a lo largo de la comparación de las reglas.

Tras ver los resultados, vamos a comparar las reglas obtenidas por NSLVOrd y Tan, de cara a comparar las reglas del estado del arte con las de la mejor ejecución.

Las reglas obtenidas por NSLVOrd son:

\begin{lstlisting}
Phase 01

R0: IF "BonyNodule" IS 'Absent' AND "LowerSymphysialExtremity" IS 'NotDefined' AND "VentralMargin" IS 'Absent'
	THEN Phase IS Ph01-18-19 with Weight = 0,506
R5: IF "UpperSymphysialExtremity" IS 'Defined' AND "BonyNodule" IS 'Absent' AND "LowerSymphysialExtremity" IS 'NotDefined' AND "VentralMargin" IS 'Absent'
	THEN Phase IS Ph01-18-19 with Weight = 0,632
R6: IF "ArticularFace" IS 'RidgesAndGrooves' AND "UpperSymphysialExtremity" IS 'NotDefined'
	THEN Phase IS Ph01-18-19 with Weight = 0,580
R25: IF "ArticularFace" IS 'RidgesAndGrooves' AND "UpperSymphysialExtremity" IS 'NotDefined' AND "DorsalPlateau" IS 'Present'
	THEN Phase IS Ph01-18-19 with Weight = 1,000

Phase02

R1: IF "ArticularFace" IS ('RidgesAndGrooves' OR 'GroovesShallow') AND "UpperSymphysialExtremity" IS 'Defined' AND "LowerSymphysialExtremity" IS 'NotDefined'
	THEN Phase IS Ph02-20-21 with Weight = 0,629
R3: IF "ArticularFace" IS 'GroovesShallow' AND "LowerSymphysialExtremity" IS 'NotDefined'
	THEN Phase IS Ph02-20-21 with Weight = 0,731
R4: IF "ArticularFace" IS 'RidgesFormation' AND "DorsalPlateau" IS 'Absent'
	THEN Phase IS Ph02-20-21 with Weight = 0,700
R7: IF "ArticularFace" IS ('RegularPorosity' OR 'RidgesFormation' OR 'RidgesAndGrooves' OR 'GroovesShallow') AND "BonyNodule" IS 'Present' AND "DorsalPlateau" IS 'Absent'
	THEN Phase IS Ph02-20-21 with Weight = 0,718
R11: IF "ArticularFace" IS ('RidgesAndGrooves' OR 'GroovesShallow') AND "BonyNodule" IS 'Absent' AND "LowerSymphysialExtremity" IS 'NotDefined' AND "DorsalPlateau" IS 'Present'
	THEN Phase IS Ph02-20-21 with Weight = 0,707

Phase03

R2: IF "BonyNodule" IS 'Present' THEN Phase IS Ph03-22-24 with Weight = 0,674
R8: IF "ArticularFace" IS ('RidgesFormation' OR 'RidgesAndGrooves' OR 'GroovesRemains') AND "LowerSymphysialExtremity" IS 'Defined' AND "VentralMargin" IS 'Absent'
	THEN Phase IS Ph03-22-24 with Weight = 1,000

Phase04

R10 : IF "LowerSymphysialExtremity" IS 'NotDefined' AND "VentralBevel" IS 'Absent' AND "VentralMargin" IS 'PartiallyFormed'
	THEN Phase IS Ph04-25-26 with Weight = 1,000
R12: IF "ArticularFace" IS ('GroovesShallow' OR 'NoGrooves') AND "UpperSymphysialExtremity" IS 'Defined' AND "BonyNodule" IS 'Absent' AND "DorsalPlateau" IS 'Present'
	THEN Phase IS Ph04-25-26 with Weight = 0,412
R17: IF "ArticularFace" IS ('GroovesShallow' OR 'GroovesRemains') AND "VentralBevel" IS ('Absent' OR 'InProcess') AND "VentralMargin" IS ('Absent' OR 'PartiallyFormed')
	THEN Phase IS Ph04-25-26 with Weight = 0,149
R21: IF "ArticularFace" IS ('GroovesShallow' OR 'NoGrooves') AND "UpperSymphysialExtremity" IS 'Defined' AND "VentralBevel" IS 'Absent' AND "VentralMargin" IS ('Absent' OR 'PartiallyFormed')
	THEN Phase IS Ph04-25-26 with Weight = 0,118

Phase05

R16: IF "IrregularPorosity" IS 'Absence' AND "LowerSymphysialExtremity" IS 'Defined' AND "VentralMargin" IS ('PartiallyFormed' OR 'FormedWithoutBonyOutgrowths')
	THEN Phase IS Ph05-27-30 with Weight = 0,103
R31: IF "IrregularPorosity" IS 'Medium' AND "VentralBevel" IS ('Absent' OR 'InProcess') AND "VentralMargin" IS ('Absent' OR 'PartiallyFormed')
	THEN Phase IS Ph05-27-30 with Weight = 0,364
R34 : IF
	THEN Phase IS Ph05-27-30 with Weight = 0,038

Phase06

R13: IF "ArticularFace" IS 'NoGrooves' AND "DorsalPlateau" IS 'Present' AND "VentralBevel" IS ('InProcess' OR 'Present')
	THEN Phase IS Ph06-31-34 with Weight = 0,556
R18: IF "ArticularFace" IS 'GroovesRemains' AND "IrregularPorosity" IS 'Absence' AND "VentralBevel" IS 'Present' AND "VentralMargin" IS ('Absent' OR 'PartiallyFormed')
	THEN Phase IS Ph06-31-34 with Weight = 0,556
R20: IF "IrregularPorosity" IS 'Medium' AND "VentralBevel" IS 'Absent' AND "VentralMargin" IS 'PartiallyFormed'
	THEN Phase IS Ph06-31-34 with Weight = 0,692

Phase07

R26: IF "IrregularPorosity" IS 'Much' AND "VentralMargin" IS ('Absent' OR 'PartiallyFormed')
	THEN Phase IS Ph07-35-39 with Weight = 1,000
R29 : IF "ArticularFace" IS 'NoGrooves' AND "VentralBevel" IS ('InProcess' OR 'Present') AND "VentralMargin" IS 'Absent'
	THEN Phase IS Ph07-35-39 with Weight = 1,000

Phase08

R15: IF "ArticularFace" IS 'GroovesRemains' AND "VentralBevel" IS ('InProcess' OR 'Present') AND "VentralMargin" IS 'FormedWithFewBonyOutgrowths'
	THEN Phase IS Ph08-40-44 with Weight = 0,263
R19: IF "IrregularPorosity" IS 'Medium' AND "VentralBevel" IS 'Absent' AND "VentralMargin" IS ('PartiallyFormed' OR 'FormedWithFewBonyOutgrowths')
	THEN Phase IS Ph08-40-44 with Weight = 0,235
R28: IF "IrregularPorosity" IS 'Medium' AND "VentralBevel" IS 'Present' AND "VentralMargin" IS 'PartiallyFormed'
	THEN Phase IS Ph08-40-44 with Weight = 1,000

Phase09

R9: IF "IrregularPorosity" IS 'Medium' AND "VentralMargin" IS ('FormedWithoutBonyOutgrowths' OR 'FormedWithFewBonyOutgrowths')
	THEN Phase IS Ph09-45-49 with Weight = 0,200
R14 : IF "ArticularFace" IS 'NoGrooves' AND "DorsalPlateau" IS 'Present' AND "VentralBevel" IS ('Absent' OR 'InProcess')
	THEN Phase IS Ph09-45-49 with Weight = 0,667
R24 : IF "ArticularFace" IS ('GroovesShallow' OR 'GroovesRemains') AND "DorsalPlateau" IS 'Present' AND "VentralBevel" IS 'Present'
	THEN Phase IS Ph09-45-49 with Weight = 0,667
R30: IF "ArticularFace" IS 'GroovesRemains' AND "VentralBevel" IS 'Absent' AND " VentralMargin" IS 'FormedWithFewBonyOutgrowths'
	THEN Phase IS Ph09-45-49 with Weight = 1,000

Phase10

R22: IF "IrregularPorosity" IS 'Much'
	THEN Phase IS Ph10-50+ with Weight = 0,228
R23: IF "VentralBevel" IS 'Absent' AND "VentralMargin" IS 'FormedWithFewBonyOutgrowths'
	THEN Phase IS Ph10-50+ with Weight = 0,714
R27: IF "IrregularPorosity" IS ('Absence' OR 'Medium') AND "VentralMargin" IS ' FormedWithRecessesAndProtrusions'
	THEN Phase IS Ph10-50+ with Weight = 1,000
R32: IF "DorsalPlateau" IS 'Absent' AND "VentralMargin" IS ('FormedWithFewBonyOutgrowths' OR 'FormedWithRecessesAndProtrusions')
	THEN Phase IS Ph10-50+ with Weight = 0,198
\end{lstlisting}

Por otro lado, las reglas obtenidas por Tan son:

\begin{lstlisting}
Rule: IF (NOT != LowerSymphysialExtremity NotDefined ) THEN (ToddPhase = Ph01-19)
Rule: ELSE IF (AND NOT AND AND AND = LowerSymphysialExtremity Defined != IrregularPorosity Much != DorsalPlaeau Present = DorsalPlaeau Absent = VentralBevel Absent ) THEN (ToddPhase = Ph02-20-21)
Rule: ELSE IF (AND NOT AND NOT = DorsalPlaeau Present = VentralBevel Present != LowerSymphysialExtremity Defined ) THEN (ToddPhase = Ph03-22-24)
Rule: ELSE IF (AND AND AND = LowerSymphysialExtremity Defined != UpperSymphysialExtremity NotDefined = IrregularPorosity Medium != LowerSymphysialExtremity NotDefined ) THEN (ToddPhase = Ph09-45-49)
Rule: ELSE IF (AND AND AND NOT AND AND != LowerSymphysialExtremity Defined = LowerSymphysialExtremity Defined = UpperSymphysialExtremity NotDefined = VentralMargin FormedWitFewRarefactions = LowerSymphysialExtremity Defined = LowerSymphysialExtremity Defined ) THEN (ToddPhase = Ph10-50-)
Rule: ELSE IF (!= IrregularPorosity Absence ) THEN (ToddPhase = Ph10-50-)
Rule: ELSE IF (AND AND = UpperSymphysialExtremity Defined != ArticularFace GroovesShallow = IrregularPorosity Medium ) THEN (ToddPhase = Ph08-40-44)
Rule: ELSE IF (AND AND NOT AND AND != VentralMargin FormedWithLotRecessesAndProtrusions = ArticularFace GroovesRest != LowerSymphysialExtremity NotDefined != LowerSymphysialExtremity NotDefined = VentralMargin FormedWithLotRecessesAndProtrusions ) THEN (ToddPhase = Ph10-50-)
Rule: ELSE IF (AND NOT AND AND AND NOT != BonyNodule Present = VentralBevel InProcess = UpperSymphysialExtremity NotDefined = VentralBevel Present ) THEN (ToddPhase = Ph09-45-49)
Rule: ELSE IF (AND AND AND AND NOT AND AND = BonyNodule Present = UpperSymphysialExtremity Defined != ArticularFace RidgesAndGrooves != BonyNodule Present = IrregularPorosity Absence = VentralMargin Absent = UpperSymphysialExtremity Defined ) THEN (ToddPhase = Ph04-25-26)
Rule: ELSE IF (AND  AND AND NOT AND NOT = BonyNodule Absent = IrregularPorosity Much != IrregularPorosity Much = ArticularFace GroovesRest = VentralBevel Present ) THEN (ToddPhase = Ph06-31-34)
Rule: ELSE IF (= VentralMargin PartiallyFormed ) THEN (ToddPhase = Ph05-27-30)
Rule: ELSE IF (AND AND AND AND != IrregularPorosity Much != DorsalPlaeau Absent = ArticularFace NoGrooves = DorsalPlaeau Present != ArticularFace RidgesFormation ) THEN (ToddPhase = Ph09-45-49)
Rule: ELSE IF (AND AND AND AND AND AND NOT != DorsalPlaeau Present = DorsalPlaeau Present != IrregularPorosity Medium != ArticularFace GroovesRest = UpperSymphysialExtremity Defined != BonyNodule Present != VentralBevel Absent ) THEN (ToddPhase = Ph05-27-30)
Rule: ELSE IF (AND AND AND AND AND AND NOT = VentralBevel Absent = UpperSymphysialExtremity Defined != IrregularPorosity Medium != VentralBevel Absent = VentralMargin FormedWithoutRarefactions != VentralBevel InProcess != DorsalPlaeau Present ) THEN (ToddPhase = Ph05-27-30)
Rule: ELSE IF (NOT AND NOT AND AND NOT AND = DorsalPlaeau Present = VentralMargin FormedWithLotRecessesAndProtrusions = UpperSymphysialExtremity NotDefined = LowerSymphysialExtremity Defined != VentralMargin PartiallyFormed ) THEN (ToddPhase = Ph04-25-26)
Rule: ELSE IF (AND AND AND AND AND = BonyNodule Absent != VentralMargin FormedWithLotRecessesAndProtrusions = VentralBevel InProcess = IrregularPorosity Much = VentralBevel InProcess ) THEN (ToddPhase = Ph06-31-34)
Rule: ELSE IF (AND AND AND AND = ArticularFace NoGrooves = VentralBevel Present != BonyNodule Present = BonyNodule Absent = VentralMargin FormedWitFewRarefactions ) THEN (ToddPhase = Ph06-31-34)
Rule: ELSE IF (AND AND AND AND AND != BonyNodule Present = VentralBevel InProcess != IrregularPorosity Much != IrregularPorosity Medium != IrregularPorosity Much ) THEN (ToddPhase = Ph05-27-30)
Rule: ELSE IF (AND AND AND NOT AND AND AND = UpperSymphysialExtremity Defined != IrregularPorosity Medium = ArticularFace NoGrooves != BonyNodule Absent = VentralMargin PartiallyFormed = UpperSymphysialExtremity Defined != IrregularPorosity Much ) THEN (ToddPhase = Ph06-31-34)
Rule: ELSE IF (AND AND NOT AND AND AND AND NOT = DorsalPlaeau Present = UpperSymphysialExtremity Defined != BonyNodule Absent != VentralBevel Absent != UpperSymphysialExtremity Defined = VentralBevel InProcess != VentralMargin FormedWitFewRarefactions ) THEN (ToddPhase = Ph04-25-26)
Rule: ELSE IF (AND AND AND != DorsalPlaeau Absent != LowerSymphysialExtremity NotDefined != DorsalPlaeau Absent = LowerSymphysialExtremity Defined ) THEN (ToddPhase = Ph08-40-44)
Rule: ELSE IF (AND AND AND = ArticularFace NoGrooves != DorsalPlaeau Present != VentralBevel InProcess ) THEN (ToddPhase = Ph09-45-49)
Rule: ELSE IF (AND AND AND AND NOT AND AND != IrregularPorosity Much = VentralMargin PartiallyFormed != UpperSymphysialExtremity Defined = BonyNodule Absent != VentralMargin FormedWithoutRarefactions = VentralBevel InProcess = BonyNodule Absent ) THEN (ToddPhase = Ph03-22-24)
Rule: ELSE IF (AND AND AND AND = LowerSymphysialExtremity Defined = VentralMargin PartiallyFormed = IrregularPorosity Absence != DorsalPlaeau Present = DorsalPlaeau Absent ) THEN (ToddPhase = Ph09-45-49)
Rule: ELSE IF (AND AND NOT = IrregularPorosity Much != VentralMargin FormedWithLotRecessesAndProtrusions = VentralMargin FormedWithoutRarefactions ) THEN (ToddPhase = Ph05-27-30)
Rule: ELSE IF (AND AND AND != IrregularPorosity Much != IrregularPorosity Much != LowerSymphysialExtremity NotDefined != ArticularFace RegularPorosity ) THEN (ToddPhase = Ph06-31-34)
Rule: ELSE IF (= LowerSymphysialExtremity Defined ) THEN (ToddPhase = Ph08-40-44)
Rule: ELSE IF (AND AND AND AND NOT != VentralBevel Absent != IrregularPorosity Much = UpperSymphysialExtremity Defined = DorsalPlaeau Absent != IrregularPorosity Much ) THEN (ToddPhase = Ph10-50-)
Rule: ELSE IF (AND AND AND NOT AND = ArticularFace GroovesShallow = LowerSymphysialExtremity Defined != VentralBevel InProcess = LowerSymphysialExtremity Defined != DorsalPlaeau Present ) THEN (ToddPhase = Ph10-50-)
Rule: ELSE IF (AND AND NOT AND != IrregularPorosity Much != VentralMargin FormedWithoutRarefactions != IrregularPorosity Medium != VentralMargin FormedWithLotRecessesAndProtrusions ) THEN (ToddPhase = Ph09-45-49)
Rule: ELSE IF (NOT AND NOT AND != VentralMargin Absent = UpperSymphysialExtremity NotDefined != IrregularPorosity Medium ) THEN (ToddPhase = Ph05-27-30)
Rule: ELSE IF (AND AND AND != VentralBevel Absent = LowerSymphysialExtremity Defined != IrregularPorosity Much = VentralBevel InProcess ) THEN (ToddPhase = Ph10-50-)
Rule: ELSE IF (AND AND NOT AND AND = UpperSymphysialExtremity Defined = ArticularFace RidgesFormation != IrregularPorosity Medium = IrregularPorosity Absence = IrregularPorosity Absence ) THEN (ToddPhase = Ph04-25-26)
Rule: ELSE IF (AND AND NOT = UpperSymphysialExtremity NotDefined = DorsalPlaeau Present != DorsalPlaeau Absent ) THEN (ToddPhase = Ph10-50-)
Rule: ELSE IF (AND AND AND != VentralBevel InProcess = BonyNodule Absent != VentralMargin FormedWithoutRarefactions = IrregularPorosity Absence ) THEN (ToddPhase = Ph09-45-49)
Rule: ELSE IF (NOT AND AND NOT != BonyNodule Present != UpperSymphysialExtremity NotDefined != BonyNodule Absent ) THEN (ToddPhase = Ph07-35-39)
Rule: ELSE (ToddPhase = Ph01-19)
\end{lstlisting}

La principal diferencia que vemos es en el motor de inferencia. En el resultado dado por el algoritmo de Tan son reglas ordenadas, que se han de resolver en orden. Si la primera regla no se dispara con un ejemplo, se pasa a la segunda, y así hasta que encontremos una regla que se dispare, devolviendo como resultado la clase del consecuente, hasta llegar a la última regla, la regla por defecto. Por otro lado, NSLVOrd devuelve un conjunto de reglas en el que, para una instancia, el antecedente puede ser verdadero para múltiples reglas, pero en lugar de resolver este caso escogiendo las reglas de forma ordenada se escogerá la regla con un mayor peso asociado.

Sabiendo como funcionan cada solución obtenida, vamos a analizar las reglas ordenadas por mayor peso de cada clase de NSLVOrd, y ver si vemos comportamientos similares con las reglas obtenidas por Tan.

Comenzando por las reglas de la primera clase, Ph01-18-19, existe una regla con un peso de $1.0$, esa regla utiliza los atributos \texttt{ArticularFace}, \texttt{UpperSymphysialExtremity} y \texttt{DorsalPlaeau}, con las condiciones de que estos atributos tengan los valores \texttt{RidgesAndGrooves}, \texttt{NotDefined} y \texttt{Present} respectivamente. Por otro lado, vemos que en las reglas de Tan solo existen dos reglas para la primera fase, la primera regla de todas, cuyo único antecedente es que \texttt{LowerSymphysialExtremity} sea \texttt{NotDefined} y la regla por defecto, al final del conjunto de reglas, aunque sin embargo es capaz de clasificar bastante bien las instancias de la primera fase. En esta fase también podemos observar que las reglas de NSLVOrd si hay ocasiones donde utilizan \texttt{LowerSymphysialExtremity}, y al igual que el algoritmo de Tan, con el valor \texttt{NotDefined}. Ambos algoritmos llegan a la conclusión de que este valor es relevante para la primera fase.

Para la segunda clase, Ph02-20-21, el algoritmo de Tan devuelve tan solo una única regla, la segunda de la lista. Esta regla se lanza si:

\begin{enumerate}
	\item No se cumple que:
		\begin{enumerate}
			\item \texttt{LowerSymphysialExtremity} sea \texttt{Defined}
			\item \texttt{IrregularPorosity} no sea \texttt{Much}
			\item \texttt{DorsalPlateau} no sea \texttt{Present}
			\item \texttt{DorsalPlateau} sea \texttt{Absent}
		\end{enumerate}
	\item Y además \texttt{VentralBevel} sea \texttt{Absent}.
\end{enumerate}

Podemos ver que aunque \texttt{IrregularPorosity} y \texttt{VentralBevel} no son usados por NSLVOrd en esta fase, tanto \texttt{LowerSymphysialExtremity} y \texttt{DorsalPlateau} se usan con los mismos valores, cuando toman el valor de \texttt{NotDefined} y \texttt{Present} respectivamente. Otro detalle que también podemos observar con esta regla, es que las reglas obtenidas por Tan podrían reducirse, ya que sabemos que \texttt{DorsalPlateau} solo tiene dos valores, \texttt{Absent} y \texttt{Present}, luego es redundante decir que sea \texttt{Present} y a la vez que no sea \texttt{Absent}.

También podemos ver que NSLVOrd en todos los casos utiliza \texttt{ArticularFace}, pidiendo que cuente principalmente con los valores \texttt{RidgesAndGrooves} o bien \texttt{GroovesShallow}. Con el análisis de fases de más adelante veremos si Tan utiliza estos valores para fases más avanzadas, o bien no lo tiene en cuenta.

Para la tercera clase, Ph03-22-24, tanto nuestra propuesta como NSLVOrd obtienen dos reglas. La regla con más peso de NSLVOrd, la regla R8 con un peso de $1.0$, utiliza \texttt{ArticularFace} con tres de sus valores, \texttt{RidgesFormation}, \texttt{RidgesAndGrooves} o \texttt{GroovesRemains}, también usa la variable \texttt{LowerSymphysialExtremity} con el valor \texttt{Defined} y por último \texttt{VentralMargin} con el valor \texttt{Absent}. En este caso ya podemos encontrar algunas diferencias más claras con el algoritmo de Tan, comenzando por la ausencia tanto de \texttt{ArticularFace} y \texttt{VentralMargin}. Además, el único atributo en común, \texttt{LowerSymphysialExtremity}, lo utilizan con valores contrarios, mientras que NSLVOrd pide el valor \texttt{Defined}, la regla obtenida por el algoritmo de Tan pide que no tome dicho valor. Si miramos la matriz de confusión obtenida en los resultados de Tan, vemos que esto seguramente sea un problema del algoritmo de Tan, ya que esta clase no parece clasificar de forma correcta ninguna instancia del conjunto de test.

Con respecto a la otra regla tanto de NSLVOrd como de Tan, en el caso de NSLVOrd tan solo utiliza \texttt{BonyNodule} con el valor \texttt{Present}, mientras que el algoritmo de Tan se utilizan más atributos y valores similares a los comentados, pero también \texttt{BonyNodule} con el valor \texttt{Present}, por lo que podemos pensar que si \texttt{BonyNodule} toma este valor, es bastante probable que sea de esta clase, sin embargo tenemos que tomar esta asunción con precaución, ya que el peso de la regla en NSLVOrd es de un $0.6$, y en el caso del algoritmo de Tan esta regla es la número 24 de 38, luego esto no ocurrirá en todas las instancias y no será un atributo que discrimine muy bien las clases.

En la cuarta clase, Ph04-25-26, de nuevo tanto Tan como NSLVOrd obtienen el mismo número de reglas, cuatro, aunque es cierto que muchas de las reglas de NSLVOrd tienen pesos muy bajos (tres de las cuatro reglas tienen un peso menor a $0.41$), mientras que únicamente una regla tiene un peso muy alto, de $1.0$.

La regla con mayor peso de NSLVOrd es bastante simple, teniendo como antecedente únicamente los atributos \texttt{LowerSymphysialExtremity}, \texttt{VentralBevel} y \texttt{VentralMargin} con los valores \texttt{NotDefined}, \texttt{Absent} y \texttt{PartiallyFormed} respectivamente. Si comparamos estos valores con las reglas de Tan, vemos como la primera regla de esta clase que aparece no tiene en común ningún atributo, a excepción de \texttt{VentralMargin}, que aparece con un valor distinto, \texttt{Absent}, aunque cercano dentro de los posibles valores de este atributo. En el resto de reglas ocurre lo mismo, y no llegan a tener atributos similares. Estas diferencias que observamos también pueden explicar las diferencias que vemos en la matriz de confusión de ambos algoritmos, donde el algoritmo de Tan apenas clasifica instancias en esta clase, mientras que NSLVOrd si que incluye muchas más instancias, incluso equivocándose bastante.

Para la quinta clase, Ph05-27-30, en NSLVOrd nos encontramos con tres reglas, siendo una de ellas la regla por defecto, y las otras dos reglas con muy poco peso, un $0.103$ y $0.364$. Por otro lado el algoritmo de Tan devuelve cinco reglas para esta fase. La regla con más prioridad en los resultados de Tan regla número doce en el sistema de reglas completo, y se trata de una regla muy simple, que \texttt{VentralMargin} tome el valor de \texttt{PartiallyFormed}. Esto concuerda con las reglas de NSLVOrd, donde en todos los casos este atributo puede tomar este valor, aunque NSLVOrd es más permisivo y permite también \texttt{PartiallyFormed} en la segunda regla y \texttt{FormedWithoutBonyOutgrowths} en la primera. Con respecto al resto de reglas, la única similitud que llama más la atención es que también aparece \texttt{VentralBevel} con el valor \texttt{InProcess} en el algoritmo de Tan, como en la regla con mayor peso de NSLVOrd, y que el algoritmo de Tan solo utiliza \texttt{IrregularPorosity} para identificar que las instancias de esta fase no toman el valor de \texttt{Medium}, mientras que en las dos reglas de NSLVOrd toman el valor de \texttt{Absent} en la regla con menor peso y \texttt{Medium} en la regla con mayor peso.

Si observamos la matriz de confusión para ambos algoritmos en esta clase, vemos que es una clase en la que ambos confunden muchas instancias de otras clases como si fueran de esta fase. Con la propuesta de NSLVOrd puede ser que se deba a la regla por defecto, y que muchas instancias no se vean cubiertas por el resto de reglas, sin embargo con el algoritmo de Tan son fallos que tiene al cubrir instancias que no debería. Habría que estudiar más en profundidad si con NSLVOrd es el mismo comportamiento que el del algoritmo de Tan, o por el contrario es la regla por defecto.


En la sexta clase, Ph06-31-34, vemos como NSLVOrd obtiene tres reglas, donde principalmente se usan los atributos \texttt{ArticularFace}, \texttt{IrregularPorosity} y \texttt{VentralBevel}. El algoritmo de Tan obtiene seis reglas para dicha clase, en las que vemos que tiene bastantes cosas en común con los resultados de NSLVOrd, por ejemplo en \texttt{IrregularPorosity}, donde el algoritmo de Tan suele tener la condición de que su valor no sea \texttt{Much}, y NSLVOrd aparecen las condiciones de que sea \texttt{Absence} o \texttt{Medium}, los otros posibles valores. También ocurre con \texttt{VentralBevel}, que ambos coinciden en que tiene que ser \texttt{Present} o \texttt{PartiallyFormed}.

Aunque encontremos estas similitudes también encontramos algunas diferencias, principalmente que el algoritmo de Tan también utiliza en la mayor parte de las reglas el atributo \texttt{BonyNodule}, en concreto con el valor \texttt{Absent}.

En la séptima clase, Ph07-35-39, NSLVOrd solo encuentra dos reglas, pero con un peso de $1.0$ en ambos casos, por lo que si encuentra instancias que disparen esta regla, tiene muy claro que se trata de esta clase. El algoritmo de Tan tan solo encuentra una regla, y es la última de todas, sin contar la regla por defecto.

La regla obtenida por Tan necesita que \texttt{BonyNodule} sea \texttt{Present}, y \texttt{UpperSymphysialExtremity} sea \texttt{NotDefined}. Estas condiciones no tienen nada que ver con las reglas obtenidas por NSLVOrd, donde se comprueba el atributo \texttt{VentralMargin} en ambas reglas, \texttt{IrregularPorosity} en la primera y \texttt{ArticularFace} junto a \texttt{VentralBevel} en la segunda.

Aunque puede parecer un comportamiento un poco raro, al comprobar la matriz de confusión de ambos resultados observamos que el algoritmo de Tan no clasifica ninguna instancia como de la séptima clase, algo esperable al tener unas condiciones tan simples y estar al final de la lista de reglas, mientras que NSLVOrd clasifica muy pocas instancias, tan solo dos, fallando la mayoría, motivo por el que las reglas tenían un peso tan alto, no son capaces de generalizar las instancias de esta clase. Es normal que no encontremos muchas semejanzas en estas reglas, ya que ningún algoritmo ha sido capaz de manejar correctamente las instancias de esta clase.

Con la octava clase, Ph08-40-44, ocurre algo muy similar que en la clase anterior. Para empezar, rápidamente podemos ver que de las tres reglas de NSLVOrd, dos de ellas, R19 y R28, son muy similares y sin embargo la diferencia de peso es muy distinta, con un peso de $0.235$ la primera regla y $1.0$ la segunda. Las diferencias son en \texttt{VentralBevel}, donde toma el valor contrario en la primera regla, y en \texttt{VentralMargin}, donde en la primera regla además de permitir el valor \texttt{PartiallyFormed} también permite \texttt{FormedWithFewBonyOutgrowths}. Esta generalización tan pequeña afecta bastante al peso de la regla, sumado a los valores de la matriz de confusión, donde la mayoría de las pocas predicciones de esta clase son errores, podemos concluir que esta clase es también muy difícil de clasificar para NSLVOrd.

Los resultados de Tan para esta clase son muy claros, obtiene tres reglas, sin embargo no llega a cubrir ninguna instancia del conjunto de test con estas reglas, por lo que también llegamos a la conclusión de que para el algoritmo de Tan es muy difícil manejar esta clase. Aun con estos resultados, las reglas no tienen atributos comunes con las reglas de NSLVOrd, y en este caso el algoritmo de Tan se centra en todas las reglas en que el atributo \texttt{LowerSymphysialExtremity} sea \texttt{Defined}.


En la clase Ph09-45-49 podemos ver que tanto el algoritmo de Tan como NSLVOrd cubren muchas instancias, sin embargo la mayoría son errores con otras clases cercanas. Si analizamos las reglas de NSLVOrd vemos que la mayoría son contradictorias, en algunas nos encontramos el atributo \texttt{VentralBevel} con valor \texttt{Absent} y en otras \texttt{Present}, el atributo \texttt{VentralMargin} también con varios valores, o \texttt{ArticularFace} con \texttt{GroovesShallow}, \texttt{GroovesRemains} o \texttt{NoGrooves}. El que estas reglas sean tan generales puede estar causando que tantas observaciones sean predichas como estas clases, y, aunque a priori pueda parecer algo malo, si sumamos esto a las pocas instancias clasificadas por las anteriores clases, en realidad estas reglas nos están describiendo las clases de fases altas, aunque no están distinguiendo como tal dentro de las clases altas, así que si podemos extraer algo de información de estas reglas. Con el algoritmo de Tan esto también ocurre, nos encontramos con reglas en las que se utilizan varias veces los mismos atributos con valores cercanos, pero diferentes, lo que hace que sean reglas que cubren muchas instancias de las clases altas.


Por último, para la clase final, Ph10-50-, ocurre exactamente al igual que con la anterior en ambos casos, tanto en Tan como en NSLVOrd son reglas demasiado generales que cubren demasiadas instancias, aunque todas ellas de clases altas. Es más, podemos ver que incluso muchas de las reglas son muy similares a las de la novena clase, mostrando aún más el solapamiento que existe entre las clases de fases altas, y lo difícil que es tomar una decisión con estas instancias.


Con esta comparación con el estado del arte podemos ver que los algoritmos propuestos tienen, en principio y aunque habría que realizar más experimentaciones en igualdad de condiciones, un mejor comportamiento al esperado por otras técnicas similares. Además también nos ha ayudado a ver que los problemas de clasificar clases altas no son exclusivos de utilizar Programación Genética para aprender las reglas, si no que en este problema distinguir las fases más altas es muy complicado, mientras que las fases bajas son más fáciles de clasificar, y ambos algoritmos proponen reglas similares para estos casos.


\newpage


\subsection{Análisis de uso de características}

Otro de los estudios de interés dentro de este problema es si realmente las diez características de Todd son buenas y necesarias para obtener un resultado. Por este motivo, se ha realizado un análisis de uso de características. Usando los resultados obtenidos por las tres mejores ejecuciones, una por algoritmo, se ha hecho un conteo de las características utilizadas:

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccccccccccc|}
\hline
\multicolumn{11}{|c|}{\textbf{Uso de características de las mejores ejecuciones escogidas}}                                                                                                                                                                                                                                                                                                                                                     \\ \hline
\multicolumn{1}{|c|}{\textbf{}}                     & \multicolumn{1}{c|}{\textbf{$x_0$}} & \multicolumn{1}{c|}{\textbf{$x_1$}} & \multicolumn{1}{c|}{\textbf{$x_2$}} & \multicolumn{1}{c|}{\textbf{$x_3$}} & \multicolumn{1}{c|}{\textbf{$x_4$}} & \multicolumn{1}{c|}{\textbf{$x_5$*}} & \multicolumn{1}{c|}{\textbf{$x_6$}} & \multicolumn{1}{c|}{\textbf{$x_7$}} & \multicolumn{1}{c|}{\textbf{$x_8$}} & \textbf{N. total de caraterísticas} \\ \hline
\multicolumn{1}{|c|}{\textbf{BJOR-SMOTE-OMAE}}      & \multicolumn{1}{c|}{4}              & \multicolumn{1}{c|}{5}              & \multicolumn{1}{c|}{2}              & \multicolumn{1}{c|}{3}              & \multicolumn{1}{c|}{3}              & \multicolumn{1}{c|}{0}              & \multicolumn{1}{c|}{0}              & \multicolumn{1}{c|}{4}              & \multicolumn{1}{c|}{3}              & 24                                  \\ \hline
\multicolumn{1}{|c|}{\textbf{FALCO-ROS-OMAE}}       & \multicolumn{1}{c|}{12}             & \multicolumn{1}{c|}{8}              & \multicolumn{1}{c|}{0}              & \multicolumn{1}{c|}{2}              & \multicolumn{1}{c|}{7}              & \multicolumn{1}{c|}{0}              & \multicolumn{1}{c|}{1}              & \multicolumn{1}{c|}{8}              & \multicolumn{1}{c|}{13}             & 51                                  \\ \hline
\multicolumn{1}{|c|}{\textbf{TAN-ROS-OMAE}}         & \multicolumn{1}{c|}{13}             & \multicolumn{1}{c|}{31}             & \multicolumn{1}{c|}{19}             & \multicolumn{1}{c|}{16}             & \multicolumn{1}{c|}{20}             & \multicolumn{1}{c|}{0}              & \multicolumn{1}{c|}{19}             & \multicolumn{1}{c|}{22}             & \multicolumn{1}{c|}{21}             & 161                                 \\ \hline
\multicolumn{1}{|c|}{\textbf{Total}}                & \multicolumn{1}{c|}{29}             & \multicolumn{1}{c|}{44}             & \multicolumn{1}{c|}{21}             & \multicolumn{1}{c|}{21}             & \multicolumn{1}{c|}{30}             & \multicolumn{1}{c|}{0}              & \multicolumn{1}{c|}{20}             & \multicolumn{1}{c|}{34}             & \multicolumn{1}{c|}{37}             & 236                                 \\ \hline
\multicolumn{1}{|c|}{\textbf{\% respecto al total}} & \multicolumn{1}{c|}{12,29\%}        & \multicolumn{1}{c|}{18,64\%}        & \multicolumn{1}{c|}{8,90\%}         & \multicolumn{1}{c|}{8,90\%}         & \multicolumn{1}{c|}{12,71\%}        & \multicolumn{1}{c|}{0,00\%}         & \multicolumn{1}{c|}{8,47\%}         & \multicolumn{1}{c|}{14,41\%}        & \multicolumn{1}{c|}{15,68\%}        &                                     \\ \hline
\end{tabular}%
}
\caption{Uso de características de los clasificadores de las mejores ejecuciones.\\ \textbf{*} La variable $x_5$, \texttt{DorsalMargin}, fue eliminada en el preprocesamiento ya que solamente tomaba un valor.} \label{tablaUsoCaracteristicas}
\end{table}

Donde:

\begin{itemize}
	\item $x_0$ es la característica \texttt{ArticularFace}.
	\item $x_1$ es la característica \texttt{IrregularPorosity}.
	\item $x_2$ es la característica \texttt{UpperSymphysialExtremity}.
	\item $x_3$ es la característica \texttt{BonyNodule}.
	\item $x_4$ es la característica \texttt{LowerSymphysialExtremity}.
	\item $x_5$ es la característica \texttt{DorsalMargin}.
	\item $x_6$ es la característica \texttt{DorsalPlaeau}.
	\item $x_7$ es la característica \texttt{VentralBevel}.
	\item $x_8$ es la característica \texttt{VentralMargin}.
\end{itemize}

Lo primero que podemos observar en la tabla \ref{tablaUsoCaracteristicas} es que el algoritmo de Bjorczuk es el que menos veces utiliza las características en las reglas, tan solo 24 veces, mientras que el algoritmo de Falco duplica ese valor con 51 apariciones, y el algoritmo de Tan triplica el uso de Falco, con 161 apariciones. Era de esperar que el algoritmo de Tan usara más característica al contar con un conjunto de reglas mucho más grande.

En nuestros resultados la variable más usada es \texttt{IrregularPorosity}, seguida por \texttt{VentralMargin}, con porcentajes de aparición de más de un $15\%$ con respecto al total. Claramente podemos distinguir en dos grupos los predictores más y menos utilizados, ya que contamos con cuatro variables con menos de un $9\%$ de uso con respecto al total de características, un total del $26,27\%$, mientras que las otras cinco características cuentan con un uso de más del $12\$$, si contamos el total, un $73,73\%$. Es decir, solo la mitad de características son utilizadas son utilizadas casi tres de cada cuatro veces que se usa una característica.

Claramente en este problema hay características que son utilizadas con una mayor frecuencia, y que seguramente tengan una mayor relevancia en la toma de decisiones. Esto concuerda con lo discutido en el estado del arte, donde varias propuestas reducían el número de predictores utilizados de nueve a cinco, como en \cite{componentBased}.



\newpage
